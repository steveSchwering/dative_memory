Lau, Clark, & Lappin (2017) -- Grammaticality, Acceptability, and Probability: A Probabilistic View of Linguistic Knowledge
    This paper examines whether acceptability judgments are better accomodated by a probabilistic grammar or a categorical grammar. The researchers examine how well different models may account for this behavior: a bigram model, a Bayesian Hidden Markov Model, a Linear Discriminant Analysis Hidden Markov Model, a two-tier Bayesian Hidden Markov Model, a Recurrent neural network, and a constituent probabilistic context free grammar -- the Stanford Parser (Klein & Manning, 2003a, b). They compare model-derived measures of sequence and word probability to human-generated acceptability scores.

    The researchers found probabilistic models are quite good at approximating acceptability judgments produced by people. Overall, approximation to human performance improved with complexity of the models, and deep learning architectures were the best.

    The researchers note that semantics and pragmatics may influence acceptability judgments of participants, though results were similar even when analyzing sentences with syntactic anomalies generated by linguists.

    It is not entirely clear to me how the researchers generated probabilities of sentences from their models.

Sprouse, Yankama, Indurkhya, Fong, & Berwick (2018) -- Colorless green ideas do sleep furiously: Gradient accepability and the nature of the grammar
    This study extends Lau, Clark, & Lappin (2017) by seeing how well probabilistic models can account for binary judgments of acceptability. The researchers conclude that there are cost-benefit tradeoffs of the probabilistic grammar approach: the probabilistic models account for some of the variance in graded acceptability judgments byt perform poorly in categorical metrics.

    Isn't this paper assuming that, by using a categorical metric, that the categorical metric is appropriate? If the sentences in the categorical dataset were coded in a gradient manner, could the probabilistic models fit well to those sentences? I find even the existence of a categorical grammar quie confusing; whether or not a probabilistic model can predict categorical acceptability is not actually interesting, so the fact that the model does not fit as well to this scoring criteria is not important.

    I am also not sure how the model fit to these different scoring criteria could or could not prove the existence of a probabilistic grammar; the fit of the models to these different scoring criteria should really have no bearing on the reality of the grammar.